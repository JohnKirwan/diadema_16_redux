---
title: "Tenerife and Berlin Diadema resolution"
author: "John D. Kirwan"
date: '2019-08-17'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores = parallel::detectCores())  # run all cores
#Sys.setenv(LOCAL_CPPFLAGS = '-march=native') # for faster Stan execution
```

Load necessary packages.

```{r Load packages, message=FALSE, warning=TRUE}
library('tidyverse')
library('rstan')
rstan::rstan_options(auto_write = TRUE)
library('brms')
library('circular')
```

Load the data. The column *target* refers to the target of the stimulus at each observation; radian and degree are the headings taken by the animal from the centre in radians and degrees respectively. Batch refers to animals collected and tested in either 2018 or 2019. Load the data and make into radians from -pi to pi. We represent the stimulus period and target half width angles in radians rather than degrees because the smaller (but still positive) values for the model predictor are preferable.


```{r}
source('Cplot2_rad.R')
```


```{r}
#df <- read_delim('Diadema-Berlin-Tenerife.csv', delim=";",col_types = "nfffcfcfn")
#df$heading_rad <- as.circular(df$heading_rad)

df <- read_delim('Da-Sp-Berlin-Tenerife-UCSB-LU.csv', delim=";",col_types = "nfffcfcfnfff")

df$arc[df$type == "DoG"] <- round(df$arc[df$type == "DoG"]*sqrt(3),0) #arc from 0-crossing to T
df$T <- df$arc / max(df$arc)
```

Plot response to a very wide stimulus (90 degree). Then remove these from the dataset.

```{r}
plot.circular(df$heading_rad[df$pattern=="unmissable"])
df <- df[df$pattern != "unmissable",]
df$huge <- NULL
```

No obvious response from the few data available.

```{r}
df$heading_rad[df$heading_rad > pi] <- round(df$heading_rad[df$heading_rad > pi] - 2*pi,3)
df$heading_rad <- as.circular(df$heading_rad)
```


Below are the different treatments of target size and contrast with the number of observations indicated by the size of the black dot.

```{r}
df %>% group_by(type) %>%
  ggplot(aes(arc,color=type)) + geom_histogram()
```

A quick look at all the data.

```{r}
rad_plot(df$heading_rad)
```

Split the control data into two so there is some for the bar and DoG conditions. 

```{r}
# for(i in 1:length(df$pattern)){
#   if(df$pattern[i] == "control"){
#    if((i %% 2) == 0){
#      df$pattern[i]  <- "DoG 0"
#      df$type[i]      <- "DoG"
#    } else {
#       df$pattern[i] <- "bar 0"
#       df$type[i]    <- "bar"
#     }
#   }
# }
# df$type <- droplevels(df$type)
# df$type <- relevel(df$type, "bar")
```


```{r}
df$type[df$pattern=="grey control"] <- "DoG"
df$type[df$pattern=="control"] <- "bar"
df$type <- droplevels(df$type)
df$type <- relevel(df$type, "bar")
```

Make a scaled version of the arc width and get the median data point.

```{r}
df$arc.s <- scale(df$arc)
arc_center <- attr(df$arc.s,"scaled:center")
arc_scale <- attr(df$arc.s,"scaled:center")
df$arc.s    <- as.numeric(df$arc.s)
```

Now, make pattern a factor 

```{r}
df$pattern <- as.factor(df$pattern)
```


### Discretization

Here, we define the sector of the circle which we consider to be the 'target' region.

```{r}
df %>% mutate(success = 0) -> df
for(i in 1:length(df$heading_rad)){           ### get tote of each using one fifth of the circle
  if(is.na(df$heading_rad[i]) == TRUE) {df$success[i] <- 0}
  else if( df$heading_rad[i] >   pi/6) {df$success[i] <- 0}    ## pi/5 beforehand
  else if( df$heading_rad[i] <= -pi/6 ){df$success[i] <- 0}  ## -pi/5 beforehand
  else{    df$success[i] <- 1}  }
```

Make dataframe for the contrast experiment and the resolution experiment. Each include the 0$&deg;$ negative control with no stimulus.



Have a look at what happens with differing Type width of the target, to get an impression of the response and to see if the result is likely to be robust to changes in the Type width.


# Resolution

```{r df Circular plots, eval=FALSE, message=FALSE, include=FALSE}
df$T <- round(df$arc / max(df$arc),2)
#d2r <- function(x){ x <- x*pi/180 } # turn degrees to radians
vonMisease <- function(x){if(x > pi){x <- x-2*pi};return(x)}
vonMapease <- function(x){modify(x,vonMisease)}
#df %>% mutate(H = d2r(heading_rad)) -> df
#df %>% mutate(H = unlist(vonMapease(H))) -> df # make headings in rad

df %>% mutate(success = 0) -> df
for(i in 1:length(df$heading_rad)){           ### get tote of each using one fifth of the circle
  if(is.na(df$heading_rad[i]) == TRUE) {df$success[i] <- 0}
  else if( df$heading_rad[i] >   pi/6) {df$success[i] <- 0}    ## pi/5 beforehand
  else if( df$heading_rad[i] <= -pi/6 ){df$success[i] <- 0}  ## -pi/5 beforehand
  else{    df$success[i] <- 1}  }
```


Make data frame for the contrast experiment and the resolution experiment. Each include the 0$&deg;$ negative control with no stimulus.

### Plot the headings

Below, we make circular plots of the vectors for each of the treatments. Code borrowed and modified from James J. Foster (University of Würzburg).

The confidence interval in these plots represents confidence intervals from bootstrapped maximum likelihood (in contrast to Sumner-Rooney *et al* (2020) where they represent circular standard deviation).

Have a look at what happens with differing Type width of the target, to get an impression of the response and to see if the result is likely to be robust to changes in the Type width.

```{r Resolution treatment summary, message=TRUE, warning=FALSE}
df %>% as_tibble %>%                 # dataframe name
  mutate(in.quad = ifelse(abs(heading_rad) < pi/4, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.pent = ifelse(abs(heading_rad) < pi/5, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.sext = ifelse(abs(heading_rad) < pi/6, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.oct  = ifelse(abs(heading_rad) < pi/8, 1, 0)) %>% # for data in radians -pi to pi
  group_by(arc,locale,type) %>%                # condition name
  summarize(#target = round(T * 180 / pi)[1],
            n_obs = n(),
            mu    = round(180*mean.circular(heading_rad)/pi,0),
            #lo.ci = round(180*mle.vonmises.bootstrap.ci(heading_rad)$mu.ci[1]/pi),
            #hi.ci = round(180*mle.vonmises.bootstrap.ci(heading_rad)$mu.ci[2]/pi),
            rho = round(rho.circular(heading_rad),2),
            #kappa = round(unlist(mle.vonmises(heading_rad)[3]),3),
            #v.stat =unlist(rayleigh.test(heading_rad,mu=0)[1]),
            v.p=     round(unlist(rayleigh.test(heading_rad,mu=0)[2]),3),
            #rayl.stat=unlist(rayleigh.test(heading_rad)[1]),
            rayl.p=  round(unlist(rayleigh.test(heading_rad)[2]),3),
            #c.mean = unlist(mean.circular(heading_rad)[1]),
            binom.p5 = round(unlist(
                binom.test(sum(in.pent),length(in.pent),
                p=1/5,alternative = "greater")[3]),3), 
            binom.p6 = round(unlist(
                binom.test(sum(in.sext),length(in.sext),
                p=1/6,alternative = "greater")[3]),3),
            binom.p8 = round(unlist(
                binom.test(sum(in.oct),length(in.oct),
                p=1/8,alternative = "greater")[3]),3),
            quad.prop = round(sum(in.quad)/length(in.quad),3),
            pent.prop = round(sum(in.pent)/length(in.pent),3),
            sext.prop = round(sum(in.sext)/length(in.sext),3),
            oct.prop  = round(sum(in.oct)/length(in.oct),3)
                ) -> circ_fun_res
## output dataframe
circ_fun_res
```






```{r}
df %>% group_by(type,species) %>%
  # dataframe name
  mutate(in.quad = ifelse(abs(heading_rad) < pi/4, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.pent = ifelse(abs(heading_rad) < pi/5, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.sext = ifelse(abs(heading_rad) < pi/6, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.oct  = ifelse(abs(heading_rad) < pi/8, 1, 0)) %>% # for data in radians -pi to pi
  group_by(arc,type,species) %>%                # condition name
  summarize(target = round(arc * 180 / pi)[1],
            quad.prop = sum(in.quad)/length(in.quad),
            pent.prop = sum(in.pent)/length(in.pent),
            sext.prop = sum(in.sext)/length(in.sext),
            oct.prop = sum(in.oct)/length(in.oct),
            binom.p6 = unlist(
                binom.test(sum(in.sext),length(in.sext),
                p=1/6,alternative = "greater")[3]),
            binom.p8 = unlist(
                binom.test(sum(in.oct),length(in.oct),
                p=1/8,alternative = "greater")[3]),
            binom.p5 = unlist(
                binom.test(sum(in.pent),length(in.pent),
                p=1/5,alternative = "greater")[3])) -> circ_fun_DoG

circ_fun_DoG %>%
  ggplot(aes(arc, sext.prop)) + geom_line(color="pink",size=3)  +
  ylab("Proportion correct responses") +
  theme_classic() + xlab("Stimulus period") +  ## data in target quadrant
  geom_line(aes(y=oct.prop), color="red")   +    ## data in target octant
  geom_line(aes(y=quad.prop), color="blue")    +    ## data in target octant
   geom_line(data=circ_fun_DoG, aes(x=arc , y=pent.prop),size=1, color="green") +
   geom_hline(yintercept = 1/6) +
   #geom_bin2d(data=df,aes(y = success, x = arc)) + # counts
   ylim(0,0.55) + facet_wrap(vars(type,species),scales = "free_x")
```



### Try with new formulation

We tried a fair few versions of the model. We settled on this version because it includes both upper and lower asymptotes and was able to converge. 4.39 approximates 2 x ln(1 - 1 / alpha), which scales the width parameter. Here alpha = 0.1, 10%, which scales width so that threshold ± width/2 includes the x axis region in which the curve rises from 10% of its maximum height above guess rate to 90% of its maximum height above guess rate.

The following non-default priors were given to brms. An informative prior was used for the lower asymptote (base) as this value should not differ much from 0.2. Upper and lower bounds were used for the aysmptotes to prevent overlap, which would make the model unidentifiable.

This is the (exponentiated) prior applied to width of the psychometric curve between 10% and 90% of its maximum height and the model threshold.


```{r}
df %>% group_by(T,type,species) %>%
  summarise(p = sum(success)/length(success)) -> props
props %>%
  ggplot(aes(x=T,y=p)) + geom_point() + theme_classic() + geom_hline(yintercept = 0.1667,color='red') + facet_wrap(vars(species,type),scales = "free_x")
```


### Prior Predictive Distribution for Resolution

Here are circular plots of these data sets.

DoG stimuli

```{r Circular plots, message=FALSE}
source('Cplot2_rad.R')
par(mfrow = c(3,ceiling( nlevels(as.factor(df$T[df$type=="DoG"])) /3)));
par(mar = c(0.5, 0.5, 0.5, 0.5) + 0.1) # bottom, left, top, right
for(i in levels(as.factor(df$arc[df$type=="DoG"])) ){
    rad_plot(df$heading_rad[df$arc == i & df$type=="DoG"],0.06)
    text(0,.6,as.character(round(as.numeric(i),2)))
 }
```



Bar stimuli

```{r Circular plots, message=FALSE}
source('Cplot2_rad.R')
par(mfrow = c(2,ceiling( nlevels(as.factor(df$T[df$type=="bar"])) /2)));
par(mar = c(0.5, 0.5, 0.5, 0.5) + 0.1) # bottom, left, top, right
for(i in levels(as.factor(df$arc[df$type=="bar"])) ){
    rad_plot(df$heading_rad[df$arc == i & df$type=="bar"],0.06)
    text(0,.6,as.character(round(as.numeric(i),2)))
 }
```



Below, we plot the possible range of values deemed by the priors and where predictions are distributed. A stimulus with the maximal target used (70 degrees) is already extremely wide. We know the base should be at 0.167 by random chance - so we put the location of the base parameter prior at this value, but allow it to vary around this point. Constraints are placed on base and lapse to prevent them overlapping. Priors on threshold and width keep these parameters within the possible range of angles. The inverse logit (logistic) function is *plogis* in base.

From previous data, we know the response rate of this species to a salient stimulus is within the range 0.3 to 0.8.

```{r}
chains=4
iter=2500
```


The model necessitates that there is some threshold value. The priors are chosen to allow any threshold from 0d up to and exceeding 180d without too much probability mass outside of this relevant range. 

```{r}
set.seed(196)
N          <- 1000
#base       <- rnorm(N,0.1,0.03)  # Base is close to random probability
base       <- rbeta(N,5,50)  # Base is close to random probability
base[base > 0.23] <- 0.23
lapse      <- rbeta(N,5,5)       # Lapse is wide range - should not overlap base rate
lapse[lapse > 0.77] <- 0.77
threshold  <- rnorm(N,2,2.5)# + sigma   # Threshold must be > 0 and can be > 1.
width      <- rnorm(N,2,2)# + sigma   # Width must be > 0 and can be > 1.
width[width < 0] <- 0                   # Varying intercepts base

plot( NULL, xlim = c(-2,6), ylim = c(0,0.9) ,
      xlab = "Scaled stimulus strength", ylab = "Proportion correct response" )
abline (h=1/6, lty=2)
for ( i  in 1:N ) curve (
        base[i] +
          (1 - base[i] - lapse[i]) *   
          plogis(4.39*(	x - threshold[i]	)	/ ( (width[i]) ) ),
   from=-2, to = 6, add = TRUE, col="blue")
```


## Main model

Can't have a random effect with only two terms!

```{r Formula}
res.psych.formula <- bf(
  success ~ base + 
            (1 - base - lapse) * inv_logit( 4.39*( arc.s - threshold	)	/ width ),
            base      ~ 1, 
            lapse     ~ 1,# + (1|locale),
            threshold ~ species*type,
            width     ~ species*type,  nl = TRUE)
```




```{r Get priors}
get_prior(res.psych.formula, data=df)
```



```{r Specify priors}
res.psych.priors  <- c(
         prior(beta(5,50),           nlpar = "base",   lb=0, ub= 0.22 ),
         prior(beta(10,10),          nlpar = "lapse" , lb=0, ub= 0.78 ),
         prior(normal(2,2.5),        nlpar= 'threshold',  class = 'b' ),
	       prior(normal(2,2),          nlpar = 'width',  lb=0, class = 'b' )
      #   prior(student_t(3,0,0.1),       nlpar = 'lapse',     class = 'sd' ),
      #   prior(exponential(10),          nlpar = 'threshold',  class = 'sd' ),
      #   prior(student_t(3,0,.1),       nlpar = 'threshold',  class = 'sd' ),
     #    prior(exponential(10),       nlpar = 'width',  class = 'sd' )
     #    prior(student_t(3,0,.1),       nlpar = 'width',      class = 'sd' )
         #,
	  #     prior(student(3,0,.5),      class = 'b', nlpar = "sigma" ) # test
         )
```



```{r Prior pred model}
res_psych_fit_pr  <- brm(res.psych.formula, data = df,
                  family = bernoulli("identity"), iter = iter,
                  chains = chains, prior = res.psych.priors, sample_prior = "only",
                  control = list(adapt_delta=0.999))

conditional_effects(res_psych_fit_pr, spaghetti=T,
                    nsamples = NULL, robust=TRUE,
                    effects = "arc.s:type")
res_psych_fit  <- add_criterion(res_psych_fit, c("loo"))
```




```{r Main model}
res_psych_fit  <- brm(res.psych.formula, data = df,
                  family = bernoulli("identity"), iter = iter,
                  chains = chains, prior = res.psych.priors, 
                  control = list(adapt_delta=0.99999))
```

According to the checks below (rhat and ESS) the model fit fine.

```{r Main summary}
summary(res_psych_fit)
```

The parameters are unimodal and the chains converged, resembling *hairy caterpillars.* Lapse is skewed, on account of the constraint imposed and because low values are perfectly plausible.

```{r}
#plot(res_psych_fit)
```



```{r Marginal plot}
conditions <-  make_conditions(df, vars = c("species","type"))

p <- conditional_effects(res_psych_fit,
          robust = TRUE,
          effects = "arc.s",
          #theme = "classic",
          conditions = conditions,
          spaghetti=FALSE,
          plot=FALSE
          )

plot(p,mean=FALSE)[[1]] + #ylim(.1,.6) + 
  geom_hline(yintercept = 1/6,alpha=.2,linetype=2) +
  facet_grid(rows=vars(species),cols=vars(type),scales="free",space="free") +
  labs(title = 'Resolution by stimulus and species') +
  xlab('Stimulus arc width') 
```

### *Empty* model without arc width predictor


```{r Empty model, include=FALSE}
res.empty.formula <- bf(
  success ~ base + 
            (1 - base - lapse) * inv_logit( 4.39*(1 - threshold	)	/ width ),
            base      ~ 1, 
            lapse     ~ 1,# + (1|locale),
            threshold ~ species*type,
            width     ~ species*type,  nl = TRUE)

res_empty_fit  <- brm(res.empty.formula, data = df, family = bernoulli("identity"),
                      iter = iter,chains = chains, prior = res.psych.priors,
                      control = list(adapt_delta=0.999))

res_empty_fit <- add_criterion(res_empty_fit, c("loo"))
```



```{r}
brms::stancode(res_psych_fit)
```


```{r}
loo_compare(res_psych_fit,res_empty_fit)
```


```{r Extract the samples}
res.psych.smpl <- posterior_samples(res_psych_fit)

bar_post <- attr(df$arc.s,"scaled:center") + res.psych.smpl$b_threshold_Intercept* attr(df$arc.s,"scaled:scale")
DoG_post <- bar_post + (attr(df$arc.s,"scaled:center") + res.psych.smpl$b_threshold_typeDoG * attr(df$arc.s,"scaled:scale"))
thresh_df <- tibble(bar=bar_post,DoG=DoG_post)
thresh_df <- gather(thresh_df,key="type",value = "threshold")

thresh_df %>% group_by(type) %>%
  ggplot(aes(x=threshold,group=type,color=type)) + geom_density() 
```



```{r}
posterior_summary(res_psych_fit,
                  pars=c("b_base_Intercept", "b_lapse_Intercept", "b_threshold_Intercept","b_width_Intercept","b_threshold_typeDoG","b_width_typeDoG"),
                  probs = c(0.025,  0.975), robust = TRUE)
```

Plot the threshold and width transformed.

### Confidence intervals of the threshold parameter.

PI (percentile interval) is a confidence interval similar to that conventionally used in frequentist statistics, which assigns equal mass to each tail.

```{r}
library('rethinking')

round(PI(thresh_df$threshold[thresh_df$type=="bar"],prob=.9),0)
round(PI(thresh_df$threshold[thresh_df$type=="DoG"],prob=.9),0)
```

HPDI (highest posterior density) is an alternative confidence interval which is especially useful is the distribution is skewed.

```{r}
round(HPDI(thresh_df$threshold[thresh_df$type=="bar"],prob=.9),0)
round(HPDI(thresh_df$threshold[thresh_df$type=="DoG"],prob=.9),0)
```

### Graphical Posterior predictive checks

Back to the main psychometric model. We check if the posterior predictions are in line with the original counts, which is so.

```{r}
  pp_check(res_psych_fit,nsamples=400, type="bars",) + theme_classic() + theme(legend.position='none')
```


```{r}
  pp_check(res_psych_fit, type = "rootogram", nsamples = 100, style = "standing", prob=0.9) +   theme_classic()
```


```{r}
ggplot(data=circ_fun_res ,aes(x=T , y=sext.prop, size=n_obs)) +
geom_point() + theme_classic() + scale_size_area(max_size = 4) + theme(legend.position="none") + ylim(0,0.7) +
  ylab("Proportion orented towards target sector") + xlab("Stimulus arc width")
```


### Plot each line from the draws and find the inflection point of each

```{r}
N = 70*3*5
vals <- array(dim=c(5000,N))
turn.idx <- vector(length = length(res.psych.smpl[,1]))
x <- seq(from=0,to=3,length.out = N)
newdat <- data.frame(T = T)

plot( NULL, xlim = c(0,3), ylim = c(0.1,.7) ,
      xlab = "Scaled stimulus strength", ylab = "Proportion correct response" )
abline (h=1/6, lty=2)
i = 1
for ( i  in 1:length(res.psych.smpl[,1])){

  vals[i,] <- res.psych.smpl$b_base_Intercept[i] +
          (1 - res.psych.smpl$b_base_Intercept[i] - res.psych.smpl$b_lapse_Intercept[i]) *
          plogis(4.39*(	x - res.psych.smpl$b_threshold_Intercept[i]	)	/
                    (res.psych.smpl$b_width_Intercept[i]) )
  lines(x,vals[i,],col = col.alpha("black",0.02))

  #infl[i] <- c(FALSE, diff(diff(vals[i,])>0)!=0)
  #points(xl[infl ], out[infl ], col="blue")

  turn.idx[i] <- which.min(diff(diff(diff(vals[i,])))) # get turning point
  }
```

### Turning points

The turning point of the curve corresponds to the threshold (in our interpretation). Above, we extracted the turning point for each iteration.

```{r}
turning.pts <- turn.idx/5
hist(turning.pts,breaks = 100)
```

Below, are two confidence intervals for the turning point. The first works best with symmetrical distributions.

```{r}
round(PI(turning.pts,prob=.95),0)
```

We prefer HPDI because the distribution is not symmetrical.

```{r}
round(HPDI(turning.pts,prob=.95),0)
```

50% credibility interval

```{r}
round(HPDI(turning.pts,prob=.5),0)
```

Compare to the value of the *threshold* parameter (transformed) for reference: They are not identical. Prefer the turning point estimate above.

```{r}
HPDI(exp(res.psych.smpl$b_threshold_Intercept)*max(df$T))
```


##### Other formulation

```{r}
res.psych.formula2 <- bf(
  success ~ base + (1 - base - lapse) * binomial(phi),
            phi ~ inv_logit(alpha + beta*T*type),
           # phi       ~ binomial(n, p),
            #phi        = inv_logit(alpha + beta*T*type),
            #X         = T*type,
            base      ~ 1, 
            lapse     ~ 1,
            alpha     ~ 1,
            beta      ~ 1,
  nl = TRUE)
```


```{r}
get_prior(res.psych.formula2, data=df)
```


```{r}
res.psych.priors2  <- c(
         prior(beta(5,50),           nlpar = "base",   lb=0, ub= 0.2),
         prior(beta(10,10),          nlpar = "lapse" , lb=0,ub= 0.75   ),
         prior(gamma(2,1.5),         nlpar= 'alpha',  class = 'b'  ),
	       prior(normal(0,2),          nlpar = 'beta',     class = 'b'  )    )
```


```{r Main model}
res_psych_fit2  <- brm(res.psych.formula2, data = df,
                  family = bernoulli("identity"), iter = iter,
                  chains = chains, prior = res.psych.priors2, 
                  control = list(adapt_delta=0.999))
```

According to the checks below (rhat and ESS) the model fit fine.

```{r}
summary(res_psych_fit2)
```

The parameters are unimodal and the chains converged, resembling *hairy caterpillars.* Lapse is skewed, on account of the constraint imposed and because low values are perfectly plausible.

```{r}
plot(res_psych_fit)
```


```{r}
conditions <- data.frame(T = seq(from=-.1,to=2,length.out=210))
plot(conditional_effects(fit, effects = "T",
                         conditions = conditions))
```


```{r}
conditional_effects(res_psych_fit, spaghetti=T, nsamples = 1000,robust=TRUE  )
```











