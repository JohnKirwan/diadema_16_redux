---
title: "Ophiocoma Spatial Resolution and Contrast Sensitivity"
author: "John D. Kirwan"
date: '2019-08-17'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores = parallel::detectCores())  # run all cores
#Sys.setenv(LOCAL_CPPFLAGS = '-march=native') # for faster Stan execution
```

Load necessary packages.

```{r Load packages, message=FALSE, warning=TRUE}
library('tidyverse')
library('rstan')
rstan::rstan_options(auto_write = TRUE)
library('brms')
library('circular')
```

Load the data. The column *target* refers to the target of the stimulus at each observation; radian and degree are the headings taken by the animal from the centre in radians and degrees respectively. Batch refers to animals collected and tested in either 2018 or 2019. Load the data and make into radians from -pi to pi. We represent the stimulus period and target half width angles in radians rather than degrees because the smaller (but still positive) values for the model predictor are preferable.


```{r}
df <- read_delim('Diadema-Berlin-Tenerife.csv', delim=";",col_types = "nfffcfcfn")
#df$heading_rad <- as.circular(df$heading_rad)
df$arc[df$type == "DoG"] <- round(df$arc[df$type == "DoG"]*sqrt(3),0) #arc from 0-crossing to T
df$T <- df$arc / max(df$arc)
```

Plot response to a very wide stimulus (90 degree). Then remove these from the dataset.

```{r}
plot.circular(df$heading_rad[df$unmissable==1])
df <- df[df$unmissable==0,]
df$unmissable <- NULL
```

No obvious response from the few data available.

```{r}
df$heading_rad[df$heading_rad > pi] <- round(df$heading_rad[df$heading_rad > pi] - 2*pi,3)
```


Below are the different treatments of target size and contrast with the number of observations indicated by the size of the black dot.

```{r}
df %>% group_by(type) %>%
  ggplot(aes(arc,color=type)) + geom_histogram()
```

```{r}
plot.circular(df$heading_rad,stack=T)
```
Split the control data into two so there is some for the bar and DoG conditions. 

```{r}
for(i in 1:length(df$pattern)){
  if(df$pattern[i] == "control"){
   if((i %% 2) != 0){
     df$pattern[i]  <- "DoG 0"
     df$type[i]      <- "DoG"
   } else {
      df$pattern[i] <- "bar 0"
      df$type[i]    <- "bar"
    }
  }
}
df$type <- droplevels(df$type)
df$type <- relevel(df$type, "DoG")
```

Now, make pattern a factor 

```{r}
df$pattern <- as.factor(df$pattern)
```


### Discretization

Here, we define the sector of the circle which we consider to be the 'target' region.

```{r}
df %>% mutate(success = 0) -> df
for(i in 1:length(df$heading_rad)){           ### get tote of each using one fifth of the circle
  if(is.na(df$heading_rad[i]) == TRUE) {df$success[i] <- 0}
  else if( df$heading_rad[i] >   pi/6) {df$success[i] <- 0}    ## pi/5 beforehand
  else if( df$heading_rad[i] <= -pi/6 ){df$success[i] <- 0}  ## -pi/5 beforehand
  else{    df$success[i] <- 1}  }
```

Make dataframe for the contrast experiment and the resolution experiment. Each include the 0$&deg;$ negative control with no stimulus.



Have a look at what happens with differing Type width of the target, to get an impression of the response and to see if the result is likely to be robust to changes in the Type width.


# Resolution

```{r df Circular plots, eval=FALSE, message=FALSE, include=FALSE}
df$T <- round(df$arc / max(df$arc),2)
#d2r <- function(x){ x <- x*pi/180 } # turn degrees to radians
vonMisease <- function(x){if(x > pi){x <- x-2*pi};return(x)}
vonMapease <- function(x){modify(x,vonMisease)}
#df %>% mutate(H = d2r(heading_rad)) -> df
#df %>% mutate(H = unlist(vonMapease(H))) -> df # make headings in rad

df %>% mutate(success = 0) -> df
for(i in 1:length(df$heading_rad)){           ### get tote of each using one fifth of the circle
  if(is.na(df$heading_rad[i]) == TRUE) {df$success[i] <- 0}
  else if( df$heading_rad[i] >   pi/6) {df$success[i] <- 0}    ## pi/5 beforehand
  else if( df$heading_rad[i] <= -pi/6 ){df$success[i] <- 0}  ## -pi/5 beforehand
  else{    df$success[i] <- 1}  }
```


Make dataframe for the contrast experiment and the resolution experiment. Each include the 0$&deg;$ negative control with no stimulus.

### Plot the headings

Below, we make circular plots of the vectors for each of the treatments. Code borrowed and modified from James J. Foster (University of Würzburg).

The confidence interval in these plots represents confidence intervals from bootstrapped maximum likelihood (in contrast to Sumner-Rooney *et al* (2020) where they represent circular standard deviation).

Have a look at what happens with differing Type width of the target, to get an impression of the response and to see if the result is likely to be robust to changes in the Type width.

```{r Resolution treatment summary, message=TRUE, warning=FALSE}
df %>% as_tibble %>%                 # dataframe name
  mutate(in.quad = ifelse(abs(heading_rad) < pi/4, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.pent = ifelse(abs(heading_rad) < pi/5, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.sext = ifelse(abs(heading_rad) < pi/6, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.oct  = ifelse(abs(heading_rad) < pi/8, 1, 0)) %>% # for data in radians -pi to pi
  group_by(arc,locale,type) %>%                # condition name
  summarize(#target = round(T * 180 / pi)[1],
            n_obs = n(),
            mu    = round(180*mean.circular(heading_rad)/pi,0),
            #lo.ci = round(180*mle.vonmises.bootstrap.ci(heading_rad)$mu.ci[1]/pi),
            #hi.ci = round(180*mle.vonmises.bootstrap.ci(heading_rad)$mu.ci[2]/pi),
            rho = round(rho.circular(heading_rad),2),
            #kappa = round(unlist(mle.vonmises(heading_rad)[3]),3),
            #v.stat =unlist(rayleigh.test(heading_rad,mu=0)[1]),
            v.p=     round(unlist(rayleigh.test(heading_rad,mu=0)[2]),3),
            #rayl.stat=unlist(rayleigh.test(heading_rad)[1]),
            rayl.p=  round(unlist(rayleigh.test(heading_rad)[2]),3),
            #c.mean = unlist(mean.circular(heading_rad)[1]),
            binom.p5 = round(unlist(
                binom.test(sum(in.pent),length(in.pent),
                p=1/5,alternative = "greater")[3]),3), 
            binom.p6 = round(unlist(
                binom.test(sum(in.sext),length(in.sext),
                p=1/6,alternative = "greater")[3]),3),
            binom.p8 = round(unlist(
                binom.test(sum(in.oct),length(in.oct),
                p=1/8,alternative = "greater")[3]),3),
            quad.prop = round(sum(in.quad)/length(in.quad),3),
            pent.prop = round(sum(in.pent)/length(in.pent),3),
            sext.prop = round(sum(in.sext)/length(in.sext),3),
            oct.prop  = round(sum(in.oct)/length(in.oct),3)
                ) -> circ_fun_res
## output dataframe
circ_fun_res
```






```{r}
df %>% filter(type == "DoG") %>%
  # dataframe name
  mutate(in.quad = ifelse(abs(heading_rad) < pi/4, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.pent = ifelse(abs(heading_rad) < pi/5, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.sext = ifelse(abs(heading_rad) < pi/6, 1, 0)) %>% # for data in radians -pi to pi
  mutate(in.oct  = ifelse(abs(heading_rad) < pi/8, 1, 0)) %>% # for data in radians -pi to pi
  group_by(arc) %>%                # condition name
  summarize(target = round(arc * 180 / pi)[1],
            quad.prop = sum(in.quad)/length(in.quad),
            pent.prop = sum(in.pent)/length(in.pent),
            sext.prop = sum(in.sext)/length(in.sext),
            oct.prop = sum(in.oct)/length(in.oct),
            binom.p6 = unlist(
                binom.test(sum(in.sext),length(in.sext),
                p=1/6,alternative = "greater")[3]),
            binom.p8 = unlist(
                binom.test(sum(in.oct),length(in.oct),
                p=1/8,alternative = "greater")[3]),
            binom.p5 = unlist(
                binom.test(sum(in.pent),length(in.pent),
                p=1/5,alternative = "greater")[3])) -> circ_fun_DoG

circ_fun_DoG %>%
  ggplot(aes(arc, sext.prop)) + geom_line(color="pink",size=3)  +
  ylab("Proportion correct responses") +
  theme_classic() + xlab("Stimulus period") +  ## data in target quadrant
  geom_line(aes(y=oct.prop), color="red")   +    ## data in target octant
  geom_line(aes(y=quad.prop), color="blue")    +    ## data in target octant
   geom_line(data=circ_fun_DoG, aes(x=arc , y=pent.prop),size=1) +
   geom_hline(yintercept = 1/6) +
   geom_bin2d(data=df,aes(y = success, x = arc)) + # counts
   ylim(0,0.55)
```

### Try with new formulation

We tried a fair few versions of the model. We settled on this version because it includes both upper and lower asymptotes and was able to converge. 4.39 approximates 2 x ln(1 - 1 / alpha), which scales the width parameter. Here alpha = 0.1, 10%, which scales width so that threshold ± width/2 includes the x axis region in which the curve rises from 10% of its maximum height above guess rate to 90% of its maximum height above guess rate.

The following non-default priors were given to brms. An informative prior was used for the lower asymptote (base) as this value should not differ much from 0.2. Upper and lower bounds were used for the aysmptotes to prevent overlap, which would make the model unidentifiable.

This is the (exponentiated) prior applied to width of the psychometric curve between 10% and 90% of its maximum height and the model threshold.


```{r}
df %>% group_by(T,type) %>%
  summarise(p = sum(success)/length(success)) -> props
props %>%
  ggplot(aes(x=T,y=p)) + geom_point() + theme_classic() + geom_hline(yintercept = 0.1667,color='red')
```


### Prior Predictive Distribution for Resolution

Here are circular plots of these data sets.

DoG stimuli

```{r Circular plots, message=FALSE}
source('Cplot2_rad.R')
par(mfrow = c(3,ceiling( nlevels(as.factor(df$T[df$type=="DoG"])) /3)));
par(mar = c(0.5, 0.5, 0.5, 0.5) + 0.1) # bottom, left, top, right
for(i in levels(as.factor(df$arc[df$type=="DoG"])) ){
    rad_plot(df$heading_rad[df$arc[df$type=="DoG"]==i],0.06)
    text(0,.6,as.character(round(as.numeric(i),2)))
 }
```

```{r Circular plots, message=FALSE}
source('Cplot2_rad.R')
for(i in levels(as.factor(df$arc[df$type=="DoG" & df$pattern=="dog 40"])) ){
    rad_plot(df$heading_rad[df$arc[df$type=="DoG"]==i],0.06)
    text(0,.6,as.character(round(as.numeric(i),2)))
 }
```

Bar stimuli

```{r Circular plots, message=FALSE}
source('Cplot2_rad.R')
par(mfrow = c(3,ceiling( nlevels(as.factor(df$T[df$type=="DoG"])) /3)));
par(mar = c(0.5, 0.5, 0.5, 0.5) + 0.1) # bottom, left, top, right
for(i in levels(as.factor(df$T[df$type=="DoG"])) ){
    rad_plot(df$heading_rad[df$T[df$type=="DoG"]==i],0.06)
    text(0,.6,as.character(round(as.numeric(i),2)))
 }
```


Below, we plot the possible range of values deemed by the priors and where predictions are distributed. A stimulus with the maximal target used (70 degrees) is already extremely wide. We know the base should be at 0.167 by random chance - so we put the location of the base parameter prior at this value, but allow it to vary around this point. Constraints are placed on base and lapse to prevent them overlapping. Priors on threshold and width keep these parameters within the possible range of angles. The inverse logit (logistic) function is *plogis* in base.

From previous data, we know the response rate of this species to a salient stimulus is within the range 0.3 to 0.8.

```{r}
chains=4
iter=2000
```


```{r}
set.seed(196)
N          <- 1000
base       <- rnorm(N,0.1,0.01)  # Base is close to random probability
base[base > 0.2] <- 0.2
lapse      <- rbeta(N,10,10)       # Lapse is wide range - should not overlap base rate
lapse[lapse > 0.7] <- 0.7
threshold  <- rgamma(N,2,1.5)    # Threshold must be > 0 and can be > 1.
width      <- rgamma(N,2,1.5)    # Width must be > 0 and can be > 1.
sigma      <- rstudent_t(N, 3, mu = 0, sigma = 1)  # Varying intercept lapse
                                   # Varying intercepts base

plot( NULL, xlim = c(-.5,3.5), ylim = c(0,0.8) ,
      xlab = "Scaled stimulus strength", ylab = "Proportion correct response" )
abline (h=1/6, lty=2)
for ( i  in 1:N ) curve (
        base[i] +
          (1 - base[i] - lapse[i]) *   
          plogis(4.39*(	x - threshold[i]	)	/ ( (width[i]) ) ),
   from=-.5, to = 3.5, add = TRUE, col = "black")
```

```{r}
res.psych.priors  <- c(
         prior(beta(5,50),           nlpar = "base",   lb=0, ub= 0.2),
         prior(beta(10,10),          nlpar = "lapse" , lb=0,ub= 0.75   ),
         prior(gamma(2,1.5),         nlpar= 'threshold',  class = 'b'   ),
	       prior(gamma(2,1.5),         nlpar = 'width',     class = 'b'   )#,
	  #     prior(student(3,0,.5),      class = 'b', nlpar = "sigma" ) # test
         )
```


### *Empty* model without predictor

Shouldn't be the T in here.

```{r Empty model, include=FALSE}
res.empty.formula <- bf(success ~
                      base +
                      (1 - base - lapse) *
                      inv_logit( 4.39*(	T - threshold)	/  width  ),
  base      ~ 1,# + (1|individual), # guess rate has a single value
	lapse     ~ 1, #+ (1|individual), # lapse rate can be different for different chicks
	threshold ~ 1, #+ (1|individual), # threshold changes with all effects
	width     ~ 1, #+ (1|individual), # threshold-width changes with all effects
                      nl = TRUE)

res_empty_fit  <- brm(res.empty.formula, data = df, family = bernoulli("identity"),
                      iter = iter,chains = chains, prior = res.psych.priors,
                      control = list(adapt_delta=0.99999))

#res_empty_fit <- add_criterion(res_empty_fit, c("loo","waic"))
```


## Main model

Try removing T*type 

```{r}
res.psych.formula <- bf(success ~
                      base +
                      (1 - base - lapse) *
                      inv_logit( 4.39*(	T*type - threshold	)	/  width  ),
  base  ~ 1, 
  lapse ~ 1 + type,
  threshold ~ 1 + type,
  width ~ 1 + type,
  nl = TRUE)
```




```{r}
get_prior(res.psych.formula, data=df)
```


```{r Main model}
res_psych_fit_pr  <- brm(res.psych.formula, data = df,
                  family = bernoulli("identity"), iter = iter,
                  chains = chains, prior = res.psych.priors, sample_prior = "only",
                  control = list(adapt_delta=0.999))

conditional_effects(res_psych_fit_pr, spaghetti=T, nsamples = NULL, robust=TRUE,
                    effects = "T:type")
#res_psych_fit  <- add_criterion(res_psych_fit, c("loo","waic"))
```




```{r Main model}
res_psych_fit  <- brm(res.psych.formula, data = df,
                  family = bernoulli("identity"), iter = iter,
                  chains = chains, prior = res.psych.priors, 
                  control = list(adapt_delta=0.999))
```

According to the checks below (rhat and ESS) the model fit fine.

```{r}
summary(res_psych_fit)
```

The parameters are unimodal and the chains converged, resembling *hairy caterpillars.* Lapse is skewed, on account of the constraint imposed and because low values are perfectly plausible.

```{r}
plot(res_psych_fit)
```



```{r}
conditional_effects(res_psych_fit, spaghetti=T, nsamples = 1000,robust=TRUE,
                    effects = "T:type")
```


```{r}
brms::stancode(res_psych_fit)
```



```{r}
loo_compare(res_psych_fit,res_empty_fit)
```


```{r Extract the samples}
res.psych.smpl <- posterior_samples(res_psych_fit)
```


```{r}
posterior_summary(res_psych_fit,
                  pars=c("b_base_Intercept", "b_lapse_Intercept", "b_threshold_Intercept","b_width_Intercept"),
                  probs = c(0.025,  0.975), robust = TRUE)
```

Plot the threshold and width transformed.

```{r}
param_trans <- function(x){
  out = x*max(df$T)
  return(out)}
mcmc_areas(res_psych_fit, pars=c("b_threshold_Intercept","b_width_Intercept"),
         point_est = "median", prob = 0.8, prob_outer = 0.95,
         transformations = param_trans) +
         ggplot2::labs(title = "Posterior distributions",
                       subtitle = "with medians and 80% intervals")
```

### Confidence intervals of the threshold parameter.

PI (percentile interval) is a confidence interval similar to that conventionally used in frequentist statistics, which assigns equal mass to each tail.

```{r}
threshold_smpl <- (res.psych.smpl$b_threshold_Intercept)*max(df$T)
round(PI(threshold_smpl,prob=.95),2)
```

HPDI (highest posterior density) is an alternative confidence interval which is especially useful is the distribution is skewed.

```{r}
round(HPDI(threshold_smpl,prob=.95),2)
```

```{r}
round(HPDI(threshold_smpl,prob=.5),2)
```

### Graphical Posterior predictive checks

Back to the main psychometric model. We check if the posterior predictions are in line with the original counts, which is so.

```{r}
  pp_check(res_psych_fit,nsamples=400, type="bars",) + theme_classic() + theme(legend.position='none')
```


```{r}
  pp_check(res_psych_fit, type = "rootogram", nsamples = 100, style = "standing", prob=0.9) +   theme_classic()
```


```{r}
ggplot(data=circ_fun_res ,aes(x=T , y=sext.prop, size=n_obs)) +
geom_point() + theme_classic() + scale_size_area(max_size = 4) + theme(legend.position="none") + ylim(0,0.7) +
  ylab("Proportion orented towards target sector") + xlab("Stimulus arc width")
```

### Bayes R-squared

```{r}
bayes_R2(res_psych_fit)
```

### Plot each line from the draws and find the inflection point of each

```{r}
N = 70*3*5
vals <- array(dim=c(5000,N))
turn.idx <- vector(length = length(res.psych.smpl[,1]))
x <- seq(from=0,to=3,length.out = N)
newdat <- data.frame(T = T)

plot( NULL, xlim = c(0,3), ylim = c(0.1,.7) ,
      xlab = "Scaled stimulus strength", ylab = "Proportion correct response" )
abline (h=1/6, lty=2)
i = 1
for ( i  in 1:length(res.psych.smpl[,1])){

  vals[i,] <- res.psych.smpl$b_base_Intercept[i] +
          (1 - res.psych.smpl$b_base_Intercept[i] - res.psych.smpl$b_lapse_Intercept[i]) *
          plogis(4.39*(	x - res.psych.smpl$b_threshold_Intercept[i]	)	/
                    (res.psych.smpl$b_width_Intercept[i]) )
  lines(x,vals[i,],col = col.alpha("black",0.02))

  #infl[i] <- c(FALSE, diff(diff(vals[i,])>0)!=0)
  #points(xl[infl ], out[infl ], col="blue")

  turn.idx[i] <- which.min(diff(diff(diff(vals[i,])))) # get turning point
  }
```

### Turning points

The turning point of the curve corresponds to the threshold (in our interpretation). Above, we extracted the turning point for each iteration.

```{r}
turning.pts <- turn.idx/5
hist(turning.pts,breaks = 100)
```

Below, are two confidence intervals for the turning point. The first works best with symmetrical distributions.

```{r}
round(PI(turning.pts,prob=.95),0)
```

We prefer HPDI because the distribution is not symmetrical.

```{r}
round(HPDI(turning.pts,prob=.95),0)
```

50% credibility interval

```{r}
round(HPDI(turning.pts,prob=.5),0)
```


Compare to the value of the *threshold* parameter (transformed) for reference: They are not identical. Prefer the turning point estimate above.

```{r}
HPDI(exp(res.psych.smpl$b_threshold_Intercept)*max(df$T))
```


#### Contrast *unmissable* and DoG 69


```{r}
centrerad <- function(x){
  if(x > pi){x = x - 2*pi
  }else{x = x}
  return(x)
  }

df$rad <- as.circular(sapply(df$heading_rad,centrerad))
df$pattern <- as.factor(df$pattern)
```

This model estimates the overall concentration. 

This model estimates the joint posterior probability of the circular expectation at each condition. 


```{r}
Mises_Type_prior.formula <- bf(theta ~ 0, kappa ~ pattern,
                         family = von_mises(link='tan_half',link_kappa = "log"))
Mises_Type_prior.prior = c(prior(normal(0,5), class = Intercept, dpar="kappa"),
                     prior(normal(0,2), class = b, dpar="kappa")  )

Mises_Type_prior.fit <- brm( Mises_Type_prior.formula,
  prior = Mises_Type_prior.prior, iter = iter,
  data = df, chains = chains,
  sample_prior = "only",
  silent=1,refresh=0,
  control = list(adapt_delta = 0.9)) 

summary(Mises_Type_prior.fit)
```

```{r}
conditional_effects(Mises_Type_prior.fit, method = "fitted",dpar = "kappa", 
                 resolution = 1000, robust = TRUE,
                 nsamples = 1000, scale='response',
                                  re_formula = NULL,ask=F)
```



Made looser priors because small treatments were estimated very low. 

```{r}


Mises_Type.formula <- bf(rad ~ 0, kappa ~ pattern, family = von_mises(link='tan_half'))
#Mises_Type.data    <- make_standata(rad ~ pattern, kappa ~ 1,
#                                  data = df, family = von_mises(link='tan_half'))

Mises_Type.prior = c(prior(normal(0,5),  class = Intercept, dpar="kappa"),
                     prior(normal(0,2), class = b, dpar="kappa")  )

Mises_Type.fit <- brm( Mises_Type.formula,
  prior = Mises_Type.prior, iter = iter,
  data = df, chains = chains,
  silent=1,refresh=0,
  control = list(adapt_delta = 0.9)) 

Mises_Type.fit <- add_criterion(Mises_Type.fit, c("loo","waic")) 
```

Plot the posterior probabilities by parameter and the Markov chains.

```{r}
plot(Mises_Type.fit,ask=F)
```

Unimodal posterior distributions with well converged Markov chains.

```{r}
summary(Mises_Type.fit)
```

ESS and Rhat values are good. Below is a graphical check of the marginal effects at the median.

```{r}
conditional_effects(Mises_Type.fit, method = "fitted",dpar = "kappa", 
                 resolution = 1000, robust = TRUE,
                 nsamples = 1000, scale='response',
                                  re_formula = NULL,ask=F)
```



The DoG 69d pattern is much more oriented than the bar or control. The bar pattern is not significantly oriented in relation to the negative control. The DoG 69d pattern is also significantly more oriented than the 55d pattern, which is not significantly more oriented than the negative control. 

This last part is surprising and takes credence from the idea that the 40 bar is not oriented. 

Posterior predictive check.

```{r}
pp_check(Mises_Type.fit, type="dens_overlay", nsamples=200)
```

#### Discretized binomial model with all categories



```{r}
Bin_Type.formula <- bf(success ~ pattern, family = bernoulli(link='logit'))
Bin_Type.prior <- c(prior(normal(0, 6), class = "b"))

Bin_Type.fit <- brm(Bin_Type.formula,
               prior = Bin_Type.prior, iter = iter,
               data = df, chains = 4,
               control = list(adapt_delta = 0.9))

Bin_Type.fit <- add_criterion(Bin_Type.fit, criterion=c('loo','waic'))
```


```{r}
conditional_effects(Bin_Type.fit, method = "fitted", 
                 resolution = 1000, robust = TRUE,
                 nsamples = 1000, scale='response',
                                  re_formula = NULL,ask=F)
```

```{r}
parnames(Bin_Type.fit)

hypotheses <- c("patterndog40 > patternbar40",
                "patterndog40 > patterncontrol",
                "patternbar40 > patterncontrol",
                "patterndog40 > patterndog55",
                "patterndog55 > patterncontrol")

hypothesis( Bin_Type.fit, hypotheses, class = "b" )
```

Same results as in the von Mises results. Did not recover the 

```{r}
rayleigh.test(df$heading_rad[df$pattern=="bar 40"])
```

```{r}
rayleigh.test(df$heading_rad[df$pattern=="bar 40"],mu=0)
```

#### A variation of the von Mises test in which mu is also estimated



```{r}
chains=4
iter=2000

Mises_mu_Type.formula <- bf(rad ~ 1, kappa ~ pattern, family = von_mises(link='tan_half'))
#Mises_mu_Type.data    <- make_standata(rad ~ pattern, kappa ~ 1,
#                                  data = df, family = von_mises(link='tan_half'))

Mises_mu_Type.prior = c(prior(normal(0,4),  class="Intercept"),
                        prior(normal(0,3),  class = Intercept, dpar="kappa"),
                        prior(normal(0,2),  class = b, dpar="kappa")  )

Mises_mu_Type.fit <- brm( Mises_mu_Type.formula,
  prior = Mises_mu_Type.prior, iter = iter,
  data = df, chains = chains,
  silent=1,refresh=0,
  control = list(adapt_delta = 0.9)) 

Mises_mu_Type.fit <- add_criterion(Mises_mu_Type.fit, c("loo","waic")) 
```

Plot the posterior probabilities by parameter and the Markov chains.

```{r}
plot(Mises_mu_Type.fit,ask=F)
```

Unimodal posterior distributions with well converged Markov chains.

```{r}
summary(Mises_mu_Type.fit)
```

ESS and Rhat values are good. Below is a graphical check of the marginal effects at the median.

```{r}
conditional_effects(Mises_mu_Type.fit, method = "fitted",dpar = "kappa", 
                 resolution = 1000, robust = TRUE,
                 nsamples = 1000, scale='response',
                                  re_formula = NULL,ask=F)
```

```{r}
parnames(Mises_mu_Type.fit)

hypotheses <- c("b_kappa_patterndog40 > b_kappa_patternbar40",
                "b_kappa_patterndog40 > b_kappa_patterncontrol",
                "b_kappa_patternbar40 > b_kappa_patterncontrol",
                "b_kappa_patterndog40 > b_kappa_patterndog55",
                "b_kappa_patterndog55 > b_kappa_patterncontrol")

hypothesis( Mises_mu_Type.fit, hypotheses, class = "" )
```



## Aside - half tan link for von Mises

```{r}
# transforms radian into scalar real
tan_half <- function(heading_rad){
  x = tan(theta/2)
  return(x)}

# transforms scalar real into radian
inv_tan_half <- function(x){
  theta = 2 * atan(x)
  return(heading_rad)}
```


